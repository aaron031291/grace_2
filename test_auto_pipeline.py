"""
Test Automatic Pipeline & Duplicate Detection

Demonstrates:
1. Upload triggers full pipeline automatically
2. Duplicate detection prevents re-ingestion
"""

import sys
import io
import requests
from pathlib import Path

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

BASE_URL = "http://localhost:8000"

print("\n" + "="*60)
print("AUTOMATIC PIPELINE & DUPLICATE DETECTION TEST")
print("="*60)

# Test 1: Upload a new small file
print("\n[Test 1] Creating and uploading a new book...")
print("-"*60)

test_content = """
# Test Business Book

## Chapter 1: Introduction
This is a test book about business strategies.

## Chapter 2: Key Concepts
Here are the main ideas and frameworks.

## Chapter 3: Action Steps
Specific tactics you can implement today.
"""

test_file = Path("test_new_book.txt")
test_file.write_text(test_content, encoding='utf-8')

try:
    with open(test_file, "rb") as f:
        response = requests.post(
            f"{BASE_URL}/api/books/upload",
            files={"file": ("test_book.txt", f, "text/plain")},
            data={
                "title": "Test Business Strategies",
                "author": "Test Author",
                "trust_level": "high"
            },
            timeout=60
        )
    
    if response.status_code == 200:
        data = response.json()
        
        print(f"‚úÖ Upload Response:")
        print(f"   Status: {data.get('status')}")
        print(f"   Document ID: {data.get('document_id')}")
        print(f"   Pages: {data.get('pages_extracted', 'N/A')}")
        print(f"   Words: {data.get('words_extracted', 'N/A')}")
        print(f"   Chunks: {data.get('chunks_created', 'N/A')}")
        print(f"   Embeddings: {data.get('embeddings_created', 'N/A')}")
        print(f"   Steps: {', '.join(data.get('steps_completed', []))}")
        
        doc_id = data.get('document_id')
        
    else:
        print(f"‚ùå Upload failed: {response.status_code}")
        print(f"   {response.text}")
        doc_id = None

except Exception as e:
    print(f"‚ùå Error: {e}")
    doc_id = None

# Test 2: Try to upload the same book (duplicate detection)
print("\n[Test 2] Uploading the SAME book again (duplicate test)...")
print("-"*60)

try:
    with open(test_file, "rb") as f:
        response = requests.post(
            f"{BASE_URL}/api/books/upload",
            files={"file": ("test_book.txt", f, "text/plain")},
            data={
                "title": "Test Business Strategies",  # Same title
                "author": "Test Author",
                "trust_level": "high"
            },
            timeout=60
        )
    
    if response.status_code == 200:
        data = response.json()
        
        if data.get('status') == 'duplicate':
            print(f"‚úÖ Duplicate Detection Working!")
            print(f"   Status: {data.get('status')}")
            print(f"   Message: {data.get('message')}")
            print(f"   Duplicate ID: {data.get('duplicate_id')}")
            print(f"   Match Type: {data.get('match_type')}")
        else:
            print(f"‚ö†Ô∏è Duplicate NOT detected (might be a bug)")
            print(f"   Status: {data.get('status')}")
    else:
        print(f"‚ùå Request failed: {response.status_code}")

except Exception as e:
    print(f"‚ùå Error: {e}")

# Test 3: Upload with similar title
print("\n[Test 3] Uploading book with SIMILAR title (fuzzy match test)...")
print("-"*60)

try:
    with open(test_file, "rb") as f:
        response = requests.post(
            f"{BASE_URL}/api/books/upload",
            files={"file": ("test_book2.txt", f, "text/plain")},
            data={
                "title": "Test Business Strategy Guide",  # Similar to "Test Business Strategies"
                "author": "Test Author",
                "trust_level": "high"
            },
            timeout=60
        )
    
    if response.status_code == 200:
        data = response.json()
        
        if data.get('status') == 'duplicate':
            print(f"‚úÖ Fuzzy Matching Working!")
            print(f"   Detected similar title: {data.get('message')}")
        else:
            print(f"‚ö†Ô∏è Similar title NOT flagged as duplicate")
            print(f"   (Similarity < 70% threshold)")

except Exception as e:
    print(f"‚ùå Error: {e}")

# Cleanup
test_file.unlink(missing_ok=True)

print("\n" + "="*60)
print("TEST SUMMARY")
print("="*60)
print("‚úÖ Automatic Pipeline: Upload triggers all steps immediately")
print("‚úÖ Duplicate Detection: Prevents re-ingesting same books")
print("‚úÖ Fuzzy Matching: Detects similar titles (>70% match)")
print("\nüìä Books in system:")

try:
    response = requests.get(f"{BASE_URL}/api/books/stats")
    if response.status_code == 200:
        stats = response.json()
        print(f"   Total: {stats.get('total_books', 0)} books")
        print(f"   Chunks: {stats.get('total_chunks', 0)}")
        print(f"   Avg Trust: {stats.get('average_trust_score', 0):.2f}")
except:
    pass

print("="*60)
print()
