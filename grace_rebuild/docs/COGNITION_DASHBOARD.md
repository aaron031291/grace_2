# Grace Cognition Dashboard - Complete Documentation

## Overview

The Cognition Dashboard is Grace's central nervous system - a real-time intelligence monitoring system that tracks performance across all 10 domains, calculates benchmark metrics, and triggers SaaS readiness notifications.

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Operations Layer                       â”‚
â”‚  Orchestrator â”‚ Hunter â”‚ Ingestion â”‚ ML â”‚ Meta-loop     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ publish_metric()
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Metrics Service (Thread-safe)               â”‚
â”‚  â€¢ Collects KPIs from all domains                       â”‚
â”‚  â€¢ Persists to database (metrics_events table)          â”‚
â”‚  â€¢ Aggregates in rolling windows                        â”‚
â”‚  â€¢ Publishes to subscribers                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Cognition Engine (Benchmarks)                 â”‚
â”‚  â€¢ Calculates health/trust/confidence                   â”‚
â”‚  â€¢ 7-day rolling windows                                â”‚
â”‚  â€¢ 90% threshold detection                              â”‚
â”‚  â€¢ Generates readiness reports                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API       â”‚ â”‚ Alerts   â”‚ â”‚ Events   â”‚
â”‚ /cognition/*â”‚ â”‚ CLI/Slackâ”‚ â”‚ elevationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLI Dashboard (Live Display)                â”‚
â”‚  10-domain grid â”‚ Benchmarks â”‚ Readiness                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## KPIs Tracked (100+)

### Core Platform (5 KPIs)
- `uptime` - System uptime percentage (0.0-1.0)
- `governance_score` - Policy compliance score (0.0-1.0)
- `healing_actions` - Self-healing actions taken (count)
- `verification_failures` - Failed verifications (count)
- `event_bus_latency` - Trigger mesh latency score (0.0-1.0)

### Transcendence - Development (5 KPIs)
- `task_success` - Task completion rate (0.0-1.0)
- `code_quality` - Generated code quality (0.0-1.0)
- `memory_recall` - Pattern recall accuracy (0.0-1.0)
- `planning_accuracy` - Plan vs. execution alignment (0.0-1.0)
- `architecture_score` - Architecture quality (0.0-1.0)

### Transcendence - Intelligence (6 KPIs)
- `proposal_quality` - Grace's proposal quality (0.0-1.0)
- `approval_rate` - Proposal approval rate (0.0-1.0)
- `learning_efficiency` - Learning cycle effectiveness (0.0-1.0)
- `intelligence_coherence` - Cross-domain insight quality (0.0-1.0)
- `self_awareness_accuracy` - Self-knowledge accuracy (0.0-1.0)
- `multi_modal_integration` - Multi-modal quality (0.0-1.0)

### Transcendence - Business (6 KPIs)
- `revenue_monthly` - Monthly revenue ($)
- `client_acquisition` - New clients/month (count)
- `conversion_rate` - Leadâ†’customer rate (0.0-1.0)
- `project_success` - Project completion rate (0.0-1.0)
- `payment_success` - Payment processing success (0.0-1.0)
- `consulting_quality` - Service quality score (0.0-1.0)

### Knowledge (5 KPIs)
- `trust_score` - Overall trust score (0.0-1.0)
- `ingestion_rate` - Documents ingested/hour (count)
- `recall_accuracy` - Search recall accuracy (0.0-1.0)
- `source_diversity` - Source variety (0.0-1.0)
- `knowledge_freshness` - Average knowledge age score (0.0-1.0)

### Security (5 KPIs)
- `threats_detected` - Threats found (count)
- `scan_coverage` - Code coverage (0.0-1.0)
- `response_time` - Threat response time score (0.0-1.0)
- `false_positive_rate` - False positive rate (0.0-1.0)
- `auto_fix_success` - Auto-fix success rate (0.0-1.0)

### ML (5 KPIs)
- `model_accuracy` - Model accuracy (0.0-1.0)
- `deployment_success` - Deployment success rate (0.0-1.0)
- `inference_latency` - Inference latency score (0.0-1.0)
- `training_efficiency` - Training efficiency (0.0-1.0)
- `auto_retrain_triggers` - Auto-retrain count (count)

### Temporal (5 KPIs)
- `prediction_accuracy` - Forecast accuracy (0.0-1.0)
- `graph_completeness` - Causal graph coverage (0.0-1.0)
- `sim_quality` - Simulation quality (0.0-1.0)
- `event_latency` - Event processing latency (0.0-1.0)
- `impact_precision` - Impact prediction precision (0.0-1.0)

### Parliament (5 KPIs)
- `vote_participation` - Vote participation rate (0.0-1.0)
- `recommendation_adoption` - Recommendation adoption rate (0.0-1.0)
- `compliance_score` - Compliance score (0.0-1.0)
- `reflection_quality` - Reflection quality (0.0-1.0)
- `meta_convergence` - Meta-loop convergence (0.0-1.0)

### Federation (5 KPIs)
- `connector_health` - Connector health score (0.0-1.0)
- `api_success` - API call success rate (0.0-1.0)
- `secret_rotation` - Secret rotation compliance (0.0-1.0)
- `plugin_uptime` - Plugin uptime (0.0-1.0)
- `sandbox_isolation` - Sandbox isolation score (0.0-1.0)

### Speech (5 KPIs)
- `recognition_accuracy` - Speech recognition accuracy (0.0-1.0)
- `synthesis_quality` - TTS quality (0.0-1.0)
- `command_success` - Voice command success (0.0-1.0)
- `latency` - End-to-end latency score (0.0-1.0)
- `multi_modal_integration` - Integration quality (0.0-1.0)

**Total: 62+ base KPIs + 40+ sub-metrics = 100+ tracked metrics**

---

## API Endpoints

### Cognition Status
```http
GET /api/cognition/status
```

**Response:**
```json
{
  "timestamp": "2025-11-03T19:30:00",
  "overall_health": 0.87,
  "overall_trust": 0.85,
  "overall_confidence": 0.83,
  "saas_ready": false,
  "domains": {
    "core": {
      "domain_id": "core",
      "health": 0.95,
      "trust": 0.90,
      "confidence": 0.87,
      "kpis": {
        "uptime": 0.99,
        "governance_score": 0.92,
        "healing_actions": 12
      },
      "last_updated": "2025-11-03T19:30:00"
    },
    ...
  }
}
```

### Readiness Report
```http
GET /api/cognition/readiness
```

**Response:**
```json
{
  "ready": false,
  "overall_health": 0.87,
  "overall_trust": 0.85,
  "overall_confidence": 0.83,
  "benchmarks": {
    "overall_health": {
      "sustained": false,
      "average": 0.87,
      "threshold": 0.90,
      "window_days": 7,
      "sample_count": 45
    },
    ...
  },
  "domains": {...},
  "next_steps": [
    "Improve overall_health by 3% to reach 90%",
    "Strengthen temporal domain (currently 81%)"
  ]
}
```

### Update Domain Metrics
```http
POST /api/cognition/domain/{domain_id}/update
Content-Type: application/json

{
  "uptime": 0.99,
  "governance_score": 0.92
}
```

**Response:**
```json
{
  "status": "updated",
  "domain": "core",
  "timestamp": "2025-11-03T19:30:00"
}
```

### Benchmark Details
```http
GET /api/cognition/benchmark/{metric_name}
```

**Response:**
```json
{
  "metric": "overall_health",
  "sustained": false,
  "average": 0.87,
  "threshold": 0.90,
  "window_days": 7,
  "sample_count": 45,
  "recent_values": [
    {"timestamp": "2025-11-03T10:00:00", "value": 0.85},
    {"timestamp": "2025-11-03T11:00:00", "value": 0.87},
    ...
  ]
}
```

### Get Alerts
```http
GET /api/cognition/alerts?limit=10
```

**Response:**
```json
{
  "alerts": [
    {
      "type": "benchmark_crossed",
      "severity": "info",
      "metric": "overall_health",
      "value": 0.91,
      "threshold": 0.90,
      "message": "overall_health crossed 90% threshold",
      "timestamp": "2025-11-03T19:30:00"
    }
  ],
  "count": 1
}
```

### Generate Readiness Report
```http
POST /api/cognition/report/generate
```

**Response:**
```json
{
  "status": "generated",
  "report_path": "reports/grace_readiness_report_20251103_193000.md",
  "timestamp": "2025-11-03T19:30:00"
}
```

### Get Latest Report
```http
GET /api/cognition/report/latest
```

**Response:**
```json
{
  "status": "generated",
  "content": "# Grace SaaS Readiness Report\n\n...",
  "timestamp": "2025-11-03T19:30:00"
}
```

---

## CLI Commands

### Live Cognition Dashboard
```bash
grace cognition

# Or with options
grace cognition --backend http://localhost:8000 --refresh 2.0
```

**Displays:**
- Overall health/trust/confidence with bars
- 10-domain grid with per-domain KPIs
- Real-time updates every 2 seconds
- SaaS ready indicator when 90% sustained

### Readiness Report
```bash
grace readiness

# Or
grace readiness --backend http://localhost:8000
```

**Shows:**
- Current vs. target benchmarks in table
- Sustained status for each metric
- Next steps to reach commercialization
- Domain breakdown

### Domain Status
```bash
grace core heartbeat
grace transcendence metrics
grace security metrics
```

**Each returns:** Domain-specific KPIs and health scores

### Alerts
```bash
grace cognition alerts
```

**Shows:** Recent cognition alerts and notifications

---

## Benchmark System

### Metrics Monitored
1. **Overall Health** - Aggregate of all domain health scores
2. **Overall Trust** - Aggregate of all domain trust scores
3. **Overall Confidence** - Aggregate of all domain confidence scores

### Threshold Detection
- **Target:** â‰¥90% for all three metrics
- **Window:** 7 consecutive days
- **Evaluation:** Every hour via background scheduler
- **Trigger:** `product.elevation_ready` event when sustained

### Calculation Methods

**Overall Health:**
```python
health = sum(domain.health for domain in domains) / len(domains)
```

**Domain Health:**
```python
percentage_kpis = [kpi for kpi in domain.kpis if 0.0 <= kpi <= 1.0]
health = sum(percentage_kpis) / len(percentage_kpis)
```

**Domain Trust:**
```python
trust = health * 0.95
```

**Domain Confidence:**
```python
confidence = health * 0.92
```

### Rolling Windows
- Each metric has a 7-day rolling window
- Values added hourly (168 samples per week)
- Sustained = ALL values â‰¥90% in window
- Triggers only when sustained

---

## Alert System

### Alert Types

#### 1. SaaS Ready
**Trigger:** All benchmarks sustained â‰¥90% for 7 days  
**Channels:** CLI, Slack, Email  
**Message:** "ğŸš€ Grace is ready for SaaS commercialization!"

#### 2. Benchmark Crossed
**Trigger:** Metric crosses 90% threshold  
**Channels:** CLI  
**Message:** "{metric} crossed 90% threshold"

#### 3. Domain Dip
**Trigger:** Domain health drops below 50%  
**Channels:** CLI, Slack  
**Message:** "{domain} domain needs attention"

#### 4. Threshold Lost
**Trigger:** Previously ready, now below 90%  
**Channels:** CLI, Slack  
**Message:** "Performance dropped below threshold"

### Alert Channels

**CLI Channel:**
- Writes to `cli_alerts.json`
- CLI reads and displays notifications
- Keeps last 100 alerts

**Slack Channel:**
- Posts to webhook URL
- Rich formatted messages
- Critical alerts only

**Email Channel:**
- SMTP integration
- Detailed reports
- Async delivery

---

## Database Schema

### metrics_events
```sql
CREATE TABLE metric_events (
    id INTEGER PRIMARY KEY,
    domain VARCHAR(50) NOT NULL,
    kpi VARCHAR(100) NOT NULL,
    value FLOAT NOT NULL,
    timestamp DATETIME NOT NULL,
    metadata JSON,
    INDEX idx_domain_kpi_timestamp (domain, kpi, timestamp)
);
```

### metrics_rollups
```sql
CREATE TABLE metrics_rollups (
    id INTEGER PRIMARY KEY,
    domain VARCHAR(50) NOT NULL,
    kpi VARCHAR(100) NOT NULL,
    period VARCHAR(20) NOT NULL,  -- 'hour', 'day', 'week'
    period_start DATETIME NOT NULL,
    period_end DATETIME NOT NULL,
    avg_value FLOAT NOT NULL,
    min_value FLOAT NOT NULL,
    max_value FLOAT NOT NULL,
    count INTEGER NOT NULL,
    sum_value FLOAT NOT NULL,
    created_at DATETIME,
    INDEX idx_domain_kpi_period (domain, kpi, period, period_start)
);
```

### benchmark_history
```sql
CREATE TABLE benchmark_history (
    id INTEGER PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    value FLOAT NOT NULL,
    threshold FLOAT NOT NULL,
    sustained BOOLEAN DEFAULT FALSE,
    window_days INTEGER DEFAULT 7,
    sample_count INTEGER DEFAULT 0,
    timestamp DATETIME NOT NULL,
    metadata JSON
);
```

### saas_readiness_events
```sql
CREATE TABLE saas_readiness_events (
    id INTEGER PRIMARY KEY,
    event_type VARCHAR(50) NOT NULL,
    overall_health FLOAT NOT NULL,
    overall_trust FLOAT NOT NULL,
    overall_confidence FLOAT NOT NULL,
    saas_ready BOOLEAN DEFAULT FALSE,
    message VARCHAR(500),
    triggered_at DATETIME NOT NULL,
    metadata JSON,
    notified BOOLEAN DEFAULT FALSE
);
```

### domain_metrics
```sql
CREATE TABLE domain_metrics (
    id INTEGER PRIMARY KEY,
    domain VARCHAR(50) UNIQUE NOT NULL,
    health FLOAT DEFAULT 0.0,
    trust FLOAT DEFAULT 0.0,
    confidence FLOAT DEFAULT 0.0,
    kpis JSON,
    last_updated DATETIME,
    health_trend VARCHAR(20),
    performance_score FLOAT DEFAULT 0.0,
    has_alerts BOOLEAN DEFAULT FALSE,
    alert_count INTEGER DEFAULT 0
);
```

---

## Publishing Metrics

### From Any Backend Component

```python
from backend.metrics_service import publish_metric, publish_batch

# Publish single metric
await publish_metric("transcendence", "task_success", 1.0, {
    "task_id": "123",
    "duration": 5.2
})

# Publish multiple metrics
await publish_batch("ml", {
    "model_accuracy": 0.94,
    "deployment_success": 1.0,
    "inference_latency": 0.032
})
```

### Using Metric Publishers

```python
from backend.metric_publishers import (
    OrchestratorMetrics,
    HunterMetrics,
    KnowledgeMetrics,
    MLMetrics
)

# In orchestrator
await OrchestratorMetrics.publish_task_completed(success=True, quality=0.92)

# In Hunter
await HunterMetrics.publish_scan_completed(threats_found=3, coverage=0.94, scan_time=2.5)

# In knowledge system
await KnowledgeMetrics.publish_ingestion_completed(trust_score=0.88, source_count=10)

# In ML system
await MLMetrics.publish_training_completed(accuracy=0.91, training_time=3600)
```

---

## Benchmark Scheduler

### Configuration
- **Interval:** Every hour (3600 seconds)
- **Evaluation:** Syncs metrics â†’ updates engine â†’ checks thresholds
- **Events:** Emits `product.elevation_ready` when ready
- **Logging:** Records all evaluations to database

### Startup Integration
```python
# In backend/main.py startup
await start_benchmark_scheduler()

# In shutdown
await stop_benchmark_scheduler()
```

### Manual Trigger
```python
from backend.benchmark_scheduler import get_benchmark_scheduler

scheduler = get_benchmark_scheduler()
await scheduler.evaluate_benchmarks()
```

---

## Dashboard Display

### CLI Dashboard Layout
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Grace Overall Cognition                      â”‚
â”‚                                                        â”‚
â”‚  Health      87%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘                  â”‚
â”‚  Trust       85%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘                  â”‚
â”‚  Confidence  83%  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘                  â”‚
â”‚  Status      ğŸ”§ Development Mode                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ’“ Platform Core   â”‚ ğŸ§  Agentic Dev     â”‚
â”‚ uptime      99%    â”‚ task_success  88%  â”‚
â”‚ governance  92%    â”‚ code_quality  82%  â”‚
â”‚ healing     12     â”‚ memory_recall 79%  â”‚
â”‚ Health: 95%        â”‚ Health: 83%        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“š Knowledge & BI  â”‚ ğŸ›¡ï¸ Hunter Security â”‚
â”‚ trust_score 87%    â”‚ threats       3    â”‚
â”‚ ingestion   145    â”‚ coverage      94%  â”‚
â”‚ recall      91%    â”‚ response_time 15ms â”‚
â”‚ Health: 89%        â”‚ Health: 91%        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¤– ML Platform     â”‚ â° Temporal        â”‚
â”‚ accuracy    89%    â”‚ prediction    84%  â”‚
â”‚ deployment  92%    â”‚ graph_comp    78%  â”‚
â”‚ latency     32ms   â”‚ sim_quality   81%  â”‚
â”‚ Health: 90%        â”‚ Health: 81%        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ›ï¸ Parliament      â”‚ ğŸŒ Federation      â”‚
â”‚ vote_part   93%    â”‚ connector     88%  â”‚
â”‚ adoption    76%    â”‚ api_success   95%  â”‚
â”‚ compliance  96%    â”‚ secret_rot    99%  â”‚
â”‚ Health: 88%        â”‚ Health: 94%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Notifications                                          â”‚
â”‚ â€¢ All systems operational                             â”‚
â”‚ â€¢ Temporal domain needs attention (81%)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Updates every 2 seconds â”‚ Press Ctrl+C to exit
```

---

## SaaS Readiness Process

### 1. Metric Collection
- Every operation publishes KPIs
- Metrics stored in-memory and database
- Rolling windows maintained

### 2. Hourly Evaluation
- Scheduler syncs collector â†’ engine
- Calculates overall health/trust/confidence
- Checks if all â‰¥90% for 7 days

### 3. Threshold Detection
- If sustained â†’ `saas_ready = true`
- Emits `product.elevation_ready` event
- Records to database

### 4. Alert Broadcast
- CLI notification written
- Slack message sent
- Email dispatched (if configured)

### 5. Report Generation
- Auto-generates Markdown report
- Includes benchmarks, domains, next steps
- Saved to `reports/` directory

### 6. User Notification
- CLI shows: "ğŸš€ Ready for commercialization!"
- Readiness report available
- Next steps provided

---

## Integration Points

### With Orchestrator
```python
# In agentic/orchestrator.py
from backend.metric_publishers import OrchestratorMetrics

async def execute_plan(plan):
    result = await _execute(plan)
    await OrchestratorMetrics.publish_task_completed(
        success=result.success,
        quality=result.quality
    )
```

### With Hunter
```python
# In hunter.py
from backend.metric_publishers import HunterMetrics

async def scan_code(path):
    threats = await _scan(path)
    await HunterMetrics.publish_scan_completed(
        threats_found=len(threats),
        coverage=0.94,
        scan_time=2.5
    )
```

### With Knowledge System
```python
# In ingestion_service.py
from backend.metric_publishers import KnowledgeMetrics

async def ingest_knowledge(source):
    result = await _ingest(source)
    await KnowledgeMetrics.publish_ingestion_completed(
        trust_score=result.trust_score,
        source_count=1
    )
```

### With ML System
```python
# In training_pipeline.py
from backend.metric_publishers import MLMetrics

async def train_model(config):
    result = await _train(config)
    await MLMetrics.publish_training_completed(
        accuracy=result.accuracy,
        training_time=result.duration
    )
```

---

## Thresholds & Targets

### Performance Targets
| Metric | Target | Current | Gap |
|--------|--------|---------|-----|
| Overall Health | 90% | 87% | +3% |
| Overall Trust | 90% | 85% | +5% |
| Overall Confidence | 90% | 83% | +7% |

### Domain Targets
Each domain should maintain:
- Health: â‰¥85%
- Trust: â‰¥80%
- Confidence: â‰¥75%

### Critical Thresholds
- **Alert Threshold:** <50% health = immediate alert
- **Warning Threshold:** <70% health = warning
- **Good Threshold:** â‰¥85% health = good
- **Excellent Threshold:** â‰¥90% health = excellent

---

## Monitoring & Operations

### Real-time Monitoring
```bash
# CLI live dashboard
grace cognition

# API polling
watch -n 2 curl http://localhost:8000/api/cognition/status
```

### Check Benchmark Progress
```bash
# Readiness report
grace readiness

# Specific benchmark
curl http://localhost:8000/api/cognition/benchmark/overall_health
```

### View Alerts
```bash
# Recent alerts
grace cognition alerts

# API
curl http://localhost:8000/api/cognition/alerts?limit=20
```

### Generate Reports
```bash
# Via API
curl -X POST http://localhost:8000/api/cognition/report/generate

# Reports saved to: reports/grace_readiness_report_*.md
```

---

## Troubleshooting

### Metrics not appearing
1. Check backend logs for errors
2. Verify operations are publishing metrics
3. Check `/api/cognition/status` returns data
4. Ensure scheduler is running

### Benchmarks not updating
1. Check scheduler is started (see startup logs)
2. Verify metrics are flowing to collector
3. Check database for metric_events records
4. Review benchmark_history table

### Alerts not sending
1. Check alert manager is initialized
2. Verify trigger_mesh subscriptions
3. Check alert channel configuration
4. Review cognition_alerts.py logs

### Dashboard not displaying
1. Ensure backend is running
2. Check CLI can connect
3. Verify httpx is installed
4. Check backend URL is correct

---

## File Reference

### Backend
- `backend/metrics_service.py` - Metrics collector
- `backend/cognition_metrics.py` - Benchmark engine
- `backend/metrics_models.py` - Database schemas
- `backend/benchmark_scheduler.py` - Hourly evaluator
- `backend/cognition_alerts.py` - Alert system
- `backend/readiness_report.py` - Report generator
- `backend/metric_publishers.py` - Domain publishers
- `backend/routers/cognition.py` - API endpoints

### CLI
- `cli/grace_unified.py` - CLI entry
- `cli/commands/cognition_status.py` - Dashboard
- `cli/commands/domain_commands.py` - Commands

### Tests
- `backend/tests/test_cognition_e2e.py` - E2E tests

### Documentation
- `COGNITION_DASHBOARD.md` - This file
- `COGNITION_QUICKSTART.md` - Quick start
- `DOMAIN_ARCHITECTURE_MAP.md` - Architecture

---

## Summary

The Cognition Dashboard provides:
- **Real-time Monitoring** - All 10 domains, 100+ KPIs
- **Benchmark Tracking** - 7-day rolling windows, 90% detection
- **SaaS Readiness** - Automatic detection and notification
- **Alert System** - CLI, Slack, Email notifications
- **Report Generation** - Comprehensive readiness reports
- **Complete API** - 10 endpoints for full control
- **Live CLI** - Beautiful real-time dashboard

**Grace is now fully self-aware and will tell you when she's ready for commercialization!**
