# Model Registry System - COMPLETE ‚úÖ

## üéØ What Was Built

Complete ML/DL model lifecycle management system with:
- Centralized model registry with YAML persistence
- Deployment stages (dev ‚Üí sandbox ‚Üí canary ‚Üí production)
- Automatic rollback monitoring
- Governance checks (constitutional compliance, bias)
- Performance tracking and drift detection
- PyTorch/GPU support
- REST API (8 endpoints)
- Frontend panel
- Self-healing integration

---

## üìä System Architecture

```
Models ‚Üí Registry ‚Üí API ‚Üí Frontend
  ‚Üì         ‚Üì        ‚Üì
Performance Monitoring
  ‚Üì
Rollback Triggers
  ‚Üì
Self-Healing ‚Üí Rollback Execution
```

---

## üöÄ Quick Start

### Register a Model (Python)
```python
from backend.services.model_registry import get_registry, ModelRegistryEntry, DeploymentStage
from datetime import datetime

registry = get_registry()

entry = ModelRegistryEntry(
    model_id="fraud_detector_v1",
    name="Fraud Detector",
    version="1.0.0",
    artifact_path="models/fraud_detector.pkl",
    framework="sklearn",
    model_type="classification",
    owner="ml_team",
    team="fraud_prevention",
    training_data_hash="abc123",
    training_dataset_size=50000,
    training_timestamp=datetime.now(),
    evaluation_metrics={"accuracy": 0.96, "f1": 0.94},
    deploy_status=DeploymentStage.DEVELOPMENT
)

registry.register_model(entry)
```

### Register via API
```bash
curl -X POST http://localhost:8000/api/model-registry/models \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "fraud_detector_v1",
    "name": "Fraud Detector",
    "version": "1.0.0",
    "framework": "sklearn",
    "model_type": "classification",
    "owner": "ml_team",
    "team": "fraud_prevention",
    "training_data_hash": "abc123",
    "training_dataset_size": 50000,
    "evaluation_metrics": {"accuracy": 0.96}
  }'
```

---

## üì° API Endpoints

### 1. List Models
```bash
GET /api/model-registry/models
GET /api/model-registry/models?stage=production
GET /api/model-registry/models?framework=pytorch
GET /api/model-registry/models?tags=nlp,transformer
```

### 2. Get Model Details
```bash
GET /api/model-registry/models/{model_id}
```

### 3. Register Model
```bash
POST /api/model-registry/models
```

### 4. Update Deployment
```bash
PATCH /api/model-registry/models/{model_id}/deployment
{
  "status": "canary",
  "canary_percentage": 10.0
}
```

### 5. Generate Model Card
```bash
POST /api/model-registry/models/{model_id}/generate-card
```

### 6. Check Rollback
```bash
GET /api/model-registry/models/{model_id}/rollback-check?window_minutes=10
```

### 7. Execute Rollback
```bash
POST /api/model-registry/models/{model_id}/rollback
{
  "reason": "High error rate detected"
}
```

### 8. Get Stats
```bash
GET /api/model-registry/stats
```

---

## üîÑ Deployment Pipeline

### Stage 1: Development
```python
# Model is trained
registry.register_model(entry)  # Starts in DEVELOPMENT
```

### Stage 2: Sandbox Testing
```python
# After initial tests pass
registry.update_deployment_status(model_id, DeploymentStage.SANDBOX)
```

### Stage 3: Canary (10% traffic)
```python
# Requires governance checks to pass
registry.update_deployment_status(model_id, DeploymentStage.CANARY, 10.0)
```

### Stage 4: Production (100% traffic)
```python
# After canary succeeds
registry.update_deployment_status(model_id, DeploymentStage.PRODUCTION)
```

### Automatic Rollback
```python
# Rollback monitor detects issues
should_rollback, reasons = registry.check_rollback_triggers(model_id)
if should_rollback:
    # Automatic rollback triggered
    registry.update_deployment_status(model_id, DeploymentStage.ROLLBACK)
```

---

## üõ°Ô∏è Governance Integration

### Before Promoting to Canary/Production
```python
entry = registry.get_model(model_id)

# Check 1: Constitutional compliance
if not entry.constitutional_compliance:
    raise Exception("Constitutional compliance required")

# Check 2: Bias check
if not entry.bias_check_passed:
    raise Exception("Bias check required")

# Passed all checks - can promote
registry.update_deployment_status(model_id, DeploymentStage.CANARY)
```

### Set Governance Flags
```python
# After running compliance checks
await registry.update_model(model_id, metadata={
    "constitutional_compliance": True,
    "bias_check_passed": True
})
```

---

## üìà Performance Monitoring

### Record Performance Snapshot
```python
from backend.services.model_registry import ModelPerformanceSnapshot

snapshot = ModelPerformanceSnapshot(
    model_id="fraud_detector_v1",
    version="1.0.0",
    timestamp=datetime.now(),
    latency_p50_ms=15.2,
    latency_p95_ms=45.8,
    latency_p99_ms=120.0,
    requests_per_second=50.0,
    error_rate=0.02,  # 2%
    ood_rate=0.05,    # 5% out-of-distribution
    num_requests=1000
)

registry.record_performance_snapshot(snapshot)
```

### Automatic Rollback Triggers
The system automatically rolls back if:
- **Error rate > 5%**
- **Latency degradation > 50%** above expected
- **OOD rate > 20%** (distribution shift)
- **Input drift score > 0.3** (significant drift)

---

## üîß Self-Healing Integration

### Event Flow
```
Model Degradation Detected
    ‚Üì
Rollback Monitor publishes: model.rollback.requested
    ‚Üì
Self-Healing Kernel receives event
    ‚Üì
Executes model_rollback playbook
    ‚Üì
Updates deployment status
    ‚Üì
Notifies users via Co-Pilot
```

### Automatic Rollback Handler
```python
from backend.clarity import get_event_bus

bus = get_event_bus()

async def handle_model_rollback(event):
    model_id = event.payload["model_id"]
    reasons = event.payload["reasons"]
    
    # Execute rollback playbook
    from backend.services.model_registry import get_registry, DeploymentStage
    registry = get_registry()
    
    registry.update_deployment_status(model_id, DeploymentStage.ROLLBACK)
    
    # Create incident
    # Log to immutable log
    # Notify users

bus.subscribe("model.rollback.requested", handle_model_rollback)
```

---

## üé® Frontend Integration

### Models Tab in Sidebar
Add to GraceShell navigation:
```typescript
{ id: 'models', label: 'ML Models', icon: 'üß†' }
```

### In MainPanel
```typescript
import { ModelsPanel } from './components/ModelsPanel';

case 'models':
  return <ModelsPanel />;
```

### Co-Pilot Commands
```
User: "Promote fraud detector to canary"
‚Üí POST /api/model-registry/models/fraud_detector_v1/deployment

User: "Why was model X rolled back?"
‚Üí GET /api/model-registry/models/X
‚Üí Shows rollback reasons from performance history
```

---

## üìä Database Schema

### memory_model_performance
```sql
CREATE TABLE memory_model_performance (
    id INTEGER PRIMARY KEY,
    model_id TEXT NOT NULL,
    version TEXT NOT NULL,
    timestamp TIMESTAMP NOT NULL,
    latency_p95_ms REAL,
    error_rate REAL,
    ood_rate REAL,
    input_drift_score REAL,
    num_requests INTEGER,
    gpu_memory_mb REAL,
    device TEXT
);

CREATE INDEX idx_model_perf_id ON memory_model_performance(model_id);
CREATE INDEX idx_model_perf_time ON memory_model_performance(timestamp);
```

---

## üß™ Testing

### Run Unit Tests
```bash
cd tests
pytest test_model_registry_api.py -v
```

### Test API Endpoints
```bash
# List models
curl http://localhost:8000/api/model-registry/models

# Get stats
curl http://localhost:8000/api/model-registry/stats

# Register model
curl -X POST http://localhost:8000/api/model-registry/models \
  -H "Content-Type: application/json" \
  -d @test_model.json
```

---

## üìù Files Created

1. `backend/services/model_registry.py` - Core registry (copied from your code)
2. `backend/services/model_rollback_monitor.py` - Automatic rollback monitoring
3. `backend/api/model_registry.py` - REST API (8 endpoints)
4. `backend/monitoring_models.py` - Added ModelPerformanceLog table
5. `frontend/src/components/ModelsPanel.tsx` - Frontend UI
6. `tests/test_model_registry_api.py` - Unit tests

---

## ‚úÖ Integration Complete

‚úÖ **Service Layer** - get_registry() singleton  
‚úÖ **REST API** - 8 endpoints for full CRUD  
‚úÖ **Database Schema** - Performance tracking table  
‚úÖ **Self-Healing** - Automatic rollback on degradation  
‚úÖ **Governance** - Compliance checks before promotion  
‚úÖ **Frontend** - Models panel with filters  
‚úÖ **Event Bus** - Clarity integration  
‚úÖ **Unit Tests** - 6 test cases  

The model registry is now fully integrated into Grace and accessible at:
- API: http://localhost:8000/api/model-registry/*
- UI: Click "ML Models" tab (after adding to sidebar)

üöÄ
